<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>TIM: Temporal and Interactive Modeling for Efficient Human-Human Motion Generation</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">TIMotion: Temporal and Interactive Framework for Efficient
              Human-Human Motion Generation</h1>
            <!-- <div class="is-size-3 publication-authors">
              UnderReview
            </div> -->
            <div style="color: red; font-size: 24px; font-weight: bold;">CVPR 2025</div> <!-- 添加的红色字体行 -->
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=xiK4nFUAAAAJ&hl=zh-CN">Yabiao
                  Wang</a><sup>1,2*</sup>,</span>
              <span class="author-block">
                <a href="">Shuo Wang</a><sup>2*</sup>,</span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?hl=zh-CN&user=2hA4X9wAAAAJ&view_op=list_works">Jiangning
                  Zhang</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="">Ke Fan</a><sup>3</sup>,
              </span>
              <span class="author-block">
                <a href="">Jiafu Wu</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="">Zhucun Xue</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="">Yong Liu</a><sup>1&#10013</sup>
              </span>
            </div>
  
            <div class="organization">
              <span class="author-block">Zhejiang University<sup>1</sup>, Tencent Youtu Lab<sup>2</sup>, Shanghai Jiao
                Tong University<sup>3</sup></span>
              <!-- <span class="author-block"><sup>2</sup>Google Research</span> -->
            </div>
  
            <div class="Equal contribution">
              <span class="author-block">* Equal contributions</span>
              <!-- <span class="author-block"><sup>2</sup>Google Research</span> -->
            </div>
            <div class="Email info">
              <span style="font-size: 1.2em; color: #5e5c5b;">&#9993;</span>
              <span class="author-block" style="font-size: smaller;">
                yabiaowang@zju.edu.cn; {leifwang,vtzhang,jiafwu}@tencent.com
              </span>
              <br>
              <span style="font-size: 1.2em; color: #5e5c5b;">&#9993;</span>
              <span class="author-block" style="font-size: smaller; ">
                slipperyfrank@sjtu.edu.cn; 12432038@zju.edu.cn; yongliu@iipc.zju.edu.cn
              </span>
            </div>
            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2408.17135" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/AIGC-Explorer/TIMotion.git"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Human-human motion generation is essential for understanding humans as social beings. Current methods fall
              into two main categories: single-person-based methods and separate modeling-based methods. To delve into
              this field, we abstract the overall generation process into a general framework MetaMotion, which consists
              of two phases: temporal modeling and interaction mixing. For temporal modeling, the single-person-based
              methods concatenate two people into a single one directly, while the separate modeling-based methods skip
              the modeling of interaction sequences. The inadequate modeling described above resulted in sub-optimal
              performance and redundant model parameters. In this paper, we introduce TIMotion (Temporal and Interactive
              Modeling), an efficient and effective framework for human-human motion generation. Specifically, we first
              propose Causal Interactive Injection to model two separate sequences as a causal sequence leveraging the
              temporal and causal properties. Then we present Role-Evolving Scanning to adjust to the change in the
              active and passive roles throughout the interaction. Finally, to generate smoother and more rational
              motion, we design Localized Pattern Amplification to capture short-term motion patterns. Extensive
              experiments on InterHuman and InterX demonstrate that our method achieves superior performance. The
              project code will be released upon acceptance.
            </p>
          </div>
        </div>
      </div>
      <div class="columns is-centered">
        <img src="./static/images/TIM.png" class="interpolation-image" alt="Interpolate start reference image." />
      </div>
      <!--/ Abstract. -->

    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">

      <!-- Quantitative Results. -->
      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-3">Quantitative Results</h2>

          <!-- Interpolating. -->
          <h3 class="title is-4">InterHuman Dataset</h3>
          <div class="content has-text-justified">
            <p>
              Quantitative evaluation on the InterHuman test set.
            </p>
          </div>
          <div class="column is-center has-text-centered">
            <img src="./static/images/results_interhuman.png" class="interpolation-image"
              alt="Interpolate start reference image." />
          </div>


          <br />
          <!--/ Interpolating. -->

          <!-- Re-rendering. -->
          <h3 class="title is-4">InterX Dataset</h3>
          <div class="content has-text-justified">
            <p>
              Quantitative evaluation on the InterX test set.
            </p>
          </div>
          <div class="columns is-centered">
            <div class="column is-center has-text-centered">
              <img src="./static/images/results_interx.png" class="interpolation-image"
                alt="Interpolate start reference image." />
            </div>
          </div>
        </div>
      </div>

    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <center>
        <h2 class="title is-3">Comparisons</h2>
      </center><br>
      <div class="content has-text-justified">
        <p>
          <b>We compare against Intergen for human-human motion generation. The synthesized motion by our proposed
            method are more consistent with the description.</b>
        </p> 
        <br> 
        <div class="content has-text-centered">
          <video id="replay-video" controls muted preload playsinline width="100%">
            <source src="./static/video/compare_22.mp4#t=0.01" type="video/mp4">
          </video>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video2" controls muted preload playsinline width="100%">
            <source src="./static/video/compare_59.mp4#t=0.01" type="video/mp4">
          </video>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video3" controls muted preload playsinline width="100%">
            <source src="./static/video/compare_53.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>

  </section>



  <section class="section">
    <div class="container is-max-desktop">
      <center>
        <h2 class="title is-3">More Generation Results</h2>
      </center><br>
      <div class="content has-text-justified">
      </div>
      <div class="columns is-multiline">
        <div class="column is-half">
          <div class="content has-text-centered">
            <div class="video-container">
              <p>two persons perform a synchronized dancing move together.</p>
              <video id="replay-video4" controls muted preload playsinline width="100%">
                <source src="./static/video/9.mp4" type="video/mp4">
              </video>
            </div>
          </div>
        </div>
        <div class="column is-half">
          <div class="content has-text-centered">
            <div class="video-container">
              <p>one person lifts the magazine in front of themselves with both hands, while the other person kicks up
                their right leg to assault the magazine.</p>
              <video id="replay-video5" controls muted preload playsinline width="100%">
                <source src="./static/video/69.mp4" type="video/mp4">
              </video>
            </div>
          </div>
        </div>
        <div class="column is-half">
          <div class="content has-text-centered">
            <div class="video-container">
              <p>one person embraces the other person's back with both arms, while the other person reciprocates the
                gesture.</p>
              <video id="replay-video6" controls muted preload playsinline width="100%">
                <source src="./static/video/17.mp4" type="video/mp4">
              </video>
            </div>
          </div>
        </div>
        <div class="column is-half">
          <div class="content has-text-centered">
            <div class="video-container">
              <p>two individuals are sparring with each other.</p>
              <video id="replay-video7" controls muted preload playsinline width="100%">
                <source src="./static/video/12.mp4" type="video/mp4">
              </video>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>


  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{wang2025TIMotion,
      title={TIMotion: Temporal and Interactive Framework for Efficient Human-Human Motion Generation}, 
      author={Yabiao Wang and Shuo Wang and Jiangning Zhang and Ke Fan and Jiafu Wu and Zhucun Xue and Yong Liu},
      booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
      year={2025}
}</code></pre>
    </div>
  </section>


  <footer class="footer">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
              href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Website source code based on the <a href="https://nerfies.github.io/"> Nerfies</a> project page. If you want
            to reuse their <a href="https://github.com/nerfies/nerfies.github.io">source code</a>, please credit them
            appropriately.
          </p>
        </div>
      </div>
    </div>
  </footer>

  <script>
    var videoContainer = document.getElementById('video-container');
    var video = document.getElementById('video');

    var videoOffset = videoContainer.offsetTop;

    window.addEventListener('scroll', function () {
      var scrollPosition = window.scrollY || window.pageYOffset;

      if (scrollPosition >= videoOffset) {
        video.play();
      } else {
        video.pause();
      }
    });
  </script>

</body>

</html>
